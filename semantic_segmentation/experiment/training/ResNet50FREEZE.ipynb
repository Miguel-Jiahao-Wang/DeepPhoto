{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"50FREEZE.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"M2sNkNkcJ9sp","colab_type":"text"},"source":["# Training using freezed Resnet50 as backbone"]},{"cell_type":"markdown","metadata":{"id":"HDn8Dq6gLYU_","colab_type":"text"},"source":["## Setup and imports"]},{"cell_type":"code","metadata":{"id":"UYKGBH4-31uu","colab_type":"code","outputId":"80d9f395-14bd-44a2-e1a6-e1ce611465eb","executionInfo":{"status":"ok","timestamp":1573402112660,"user_tz":-60,"elapsed":1157,"user":{"displayName":"Jørgen LUND","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCl34-6f7cAnGnbJZYUpTfImEMzN-NAXzrF8r1_bw=s64","userId":"05384122703626563336"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s77TdXYH5Yf5","colab_type":"code","outputId":"f3d28c4c-54b2-4d1d-c3cb-00fd9c9883b7","executionInfo":{"status":"ok","timestamp":1573402112665,"user_tz":-60,"elapsed":1142,"user":{"displayName":"Jørgen LUND","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCl34-6f7cAnGnbJZYUpTfImEMzN-NAXzrF8r1_bw=s64","userId":"05384122703626563336"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/DeepLearningX/gitclone/light-weight-refinenet/src"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/DeepLearningX/gitclone/light-weight-refinenet/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C-X2w5mCvJv1","colab_type":"code","colab":{}},"source":["# general libs\n","import argparse\n","import logging\n","import os\n","import random\n","import re\n","import sys\n","import time\n","\n","# misc\n","import cv2\n","import numpy as np\n","\n","# pytorch libs\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import confusion_matrix\n","\n","# custom libs\n","from util import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DiDWxTomLaDH","colab_type":"text"},"source":["## Methods for training"]},{"cell_type":"code","metadata":{"id":"UIIwnxyc-ma8","colab_type":"code","colab":{}},"source":["# defining methods for training \n","sys.path.append(\"..\")\n","\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, random_split\n","# Custom libraries\n","from datasets import NYUDataset as Dataset\n","from datasets import Pad, RandomCrop, RandomMirror, ResizeShorterScale, ToTensor, Normalise\n","\n","def create_segmenter(\n","    net, pretrained, num_classes\n","    ):\n","    \"\"\"Create Encoder; for now only ResNet [50,101,152]\"\"\"\n","    from models.resnet import rf_lw50, rf_lw101, rf_lw152\n","    if str(net) == '50':\n","        return rf_lw50(num_classes, imagenet=pretrained)\n","    elif str(net) == '101':\n","        return rf_lw101(num_classes, imagenet=pretrained)\n","    elif str(net) == '152':\n","        return rf_lw152(num_classes, imagenet=pretrained)\n","    elif str(net) == 'Mob':\n","        return mbv2(num_classes, pretrained=pretrained)\n","    else:\n","        raise ValueError(\"{} is not supported\".format(str(net)))\n","\n","def create_loaders(\n","    train_dir, val_dir, train_list, val_list,\n","    shorter_side, crop_size, low_scale, high_scale,\n","    normalise_params, batch_size, num_workers, ignore_label\n","    ):\n","    \"\"\"\n","    Args:\n","      train_dir (str) : path to the root directory of the training set.\n","      val_dir (str) : path to the root directory of the validation set.\n","      train_list (str) : path to the training list.\n","      val_list (str) : path to the validation list.\n","      shorter_side (int) : parameter of the shorter_side resize transformation.\n","      crop_size (int) : square crop to apply during the training.\n","      low_scale (float) : lowest scale ratio for augmentations.\n","      high_scale (float) : highest scale ratio for augmentations.\n","      normalise_params (list / tuple) : img_scale, img_mean, img_std.\n","      batch_size (int) : training batch size.\n","      num_workers (int) : number of workers to parallelise data loading operations.\n","      ignore_label (int) : label to pad segmentation masks with\n","\n","    Returns:\n","      train_loader, val loader\n","\n","    \"\"\"\n","\n","    ## Transformations during training ##\n","    composed_trn = transforms.Compose([ResizeShorterScale(shorter_side, low_scale, high_scale),\n","                                    Pad(crop_size, [123.675, 116.28 , 103.53], ignore_label),\n","                                    RandomMirror(),\n","                                    RandomCrop(crop_size),\n","                                    Normalise(*normalise_params),\n","                                    ToTensor()])\n","    composed_val = transforms.Compose([Normalise(*normalise_params),\n","                                    ToTensor()])\n","    ## Training and validation sets ##\n","    trainset = Dataset(data_file=train_list,\n","                       data_dir=train_dir,\n","                       transform_trn=composed_trn,\n","                       transform_val=composed_val)\n","\n","    valset = Dataset(data_file=val_list,\n","                         data_dir=val_dir,\n","                         transform_trn=None,\n","                         transform_val=composed_val)\n","    logger.info(\" Created train set = {} examples, val set = {} examples\"\n","                .format(len(trainset), len(valset)))\n","    ## Training and validation loaders ##\n","    train_loader = DataLoader(trainset,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=num_workers,\n","                              pin_memory=True,\n","                              drop_last=True)\n","    val_loader = DataLoader(valset,\n","                            batch_size=1,\n","                            shuffle=False,\n","                            num_workers=num_workers,\n","                            pin_memory=True)\n","    return train_loader, val_loader\n","\n","def create_optimisers(\n","    lr_enc, lr_dec,\n","    mom_enc, mom_dec,\n","    wd_enc, wd_dec,\n","    param_enc, param_dec,\n","    optim_dec\n","    ):\n","    \"\"\"Create optimisers for encoder, decoder and controller\"\"\"\n","    optim_enc = torch.optim.SGD(param_enc, lr=lr_enc, momentum=mom_enc,\n","                                weight_decay=wd_enc)\n","    if optim_dec == 'sgd':\n","        optim_dec = torch.optim.SGD(param_dec, lr=lr_dec,\n","                                    momentum=mom_dec, weight_decay=wd_dec)\n","    elif optim_dec == 'adam':\n","        optim_dec = torch.optim.Adam(param_dec, lr=lr_dec, weight_decay=wd_dec, eps=1e-3)\n","    return optim_enc, optim_dec\n","\n","def load_ckpt(\n","    ckpt_path, ckpt_dict\n","    ):\n","    best_val = epoch_start = 0\n","    if os.path.exists(CKPT_PATH):\n","        ckpt = torch.load(ckpt_path)\n","        for (k, v) in ckpt_dict.items():\n","            if k in ckpt:\n","                v.load_state_dict(ckpt[k])\n","        best_val = ckpt.get('best_val', 0)\n","        epoch_start = ckpt.get('epoch_start', 0)\n","        logger.info(\" Found checkpoint at {} with best_val {:.4f} at epoch {}\".\n","            format(\n","                ckpt_path, best_val, epoch_start\n","            ))\n","    return best_val, epoch_start\n","\n","def train_segmenter(\n","    segmenter, train_loader, optim_enc, optim_dec,\n","    epoch, segm_crit, freeze_bn\n","    ):\n","    \"\"\"Training segmenter\n","\n","    Args:\n","      segmenter (nn.Module) : segmentation network\n","      train_loader (DataLoader) : training data iterator\n","      optim_enc (optim) : optimiser for encoder\n","      optim_dec (optim) : optimiser for decoder\n","      epoch (int) : current epoch\n","      segm_crit (nn.Loss) : segmentation criterion\n","      freeze_bn (bool) : whether to keep BN params intact\n","\n","    \"\"\"\n","    train_loader.dataset.set_stage('train')\n","    segmenter.train()\n","    if freeze_bn:\n","        for m in segmenter.modules():\n","            if isinstance(m, nn.BatchNorm2d):\n","                m.eval()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    for i, sample in enumerate(train_loader):\n","        start = time.time()\n","        input = sample['image'].cuda()\n","        target = sample['mask'].cuda()\n","        input_var = torch.autograd.Variable(input).float()\n","        target_var = torch.autograd.Variable(target).long()\n","        # Compute output\n","        output = segmenter(input_var)\n","        output = nn.functional.interpolate(output, size=target_var.size()[1:], mode='bilinear', align_corners=False)\n","        soft_output = nn.LogSoftmax()(output)\n","        # Compute loss and backpropagate\n","        loss = segm_crit(soft_output, target_var)\n","        optim_enc.zero_grad()\n","        optim_dec.zero_grad()\n","        loss.backward()\n","        optim_enc.step()\n","        optim_dec.step()\n","        losses.update(loss.item())\n","        batch_time.update(time.time() - start)\n","        if i % PRINT_EVERY == 0:\n","            logger.info(' Train epoch: {} [{}/{}]\\t'\n","                        'Avg. Loss: {:.3f}\\t'\n","                        'Avg. Time: {:.3f}'.format(\n","                            epoch, i, len(train_loader),\n","                            losses.avg, batch_time.avg\n","                        ))\n","def compute_iu(cm):\n","    \"\"\"Compute IU from confusion matrix.\n","\n","    Args:\n","      cm (Tensor) : square confusion matrix.\n","\n","    Returns:\n","      IU vector (Tensor).\n","\n","    \"\"\"\n","    pi = 0\n","    gi = 0\n","    ii = 0\n","    denom = 0\n","    n_classes = cm.shape[0]\n","    IU = np.ones(n_classes)\n","    \n","    for i in range(n_classes):\n","        pi = sum(cm[:, i])\n","        gi = sum(cm[i, :])\n","        ii = cm[i, i]\n","        denom = pi + gi - ii\n","        if denom > 0:\n","            IU[i] = ii / denom\n","    return IU\n","\n","def validate(\n","    segmenter, val_loader, epoch, num_classes=-1\n","    ):\n","    \"\"\"Validate segmenter\n","\n","    Args:\n","      segmenter (nn.Module) : segmentation network\n","      val_loader (DataLoader) : training data iterator\n","      epoch (int) : current epoch\n","      num_classes (int) : number of classes to consider\n","\n","    Returns:\n","      Mean IoU (float)\n","    \"\"\"\n","    val_loader.dataset.set_stage('val')\n","    segmenter.eval()\n","    cm = np.zeros((num_classes, num_classes), dtype=int)\n","    with torch.no_grad():\n","        for i, sample in enumerate(val_loader):\n","            start = time.time()\n","            input = sample['image']\n","            target = sample['mask']\n","            input_var = torch.autograd.Variable(input).float().cuda()\n","            # Compute output\n","            output = segmenter(input_var)\n","            output = cv2.resize(output[0, :num_classes].data.cpu().numpy().transpose(1, 2, 0),\n","                                target.size()[1:][::-1],\n","                                interpolation=cv2.INTER_CUBIC).argmax(axis=2).astype(np.uint8)\n","            # Compute IoU\n","            gt = target[0].data.cpu().numpy().astype(np.uint8)\n","            gt_idx = gt < num_classes # Ignore every class index larger than the number of classes\n","            cm += confusion_matrix(output[gt_idx], gt[gt_idx])\n","\n","            # if i % PRINT_EVERY == 0:\n","            #     logger.info(' Val epoch: {} [{}/{}]\\t'\n","            #                 'Mean IoU: {:.3f}'.format(\n","            #                     epoch, i, len(val_loader),\n","            #                     compute_iu(cm).mean()\n","            #                 ))\n","\n","    ious = compute_iu(cm)\n","    logger.info(\" IoUs: {}\".format(ious))\n","    miou = np.mean(ious)\n","\n","    miou_path = '/content/drive/My Drive/DeepLearningX/models/ResNet/mious_res{}_{}.txt'.format(ENC, FREEZED)\n","\n","    with open(miou_path, 'a') as f:\n","      f.write(\"{}\\n\".format(miou))\n","\n","    logger.info(' Val epoch: {}\\tMean IoU: {:.3f}'.format(\n","                                epoch, miou))\n","    return miou\n","\n","def main():\n","    logging.basicConfig(level=logging.INFO)\n","    global logger #, args\n","    # args = get_arguments()\n","    logger = logging.getLogger(__name__)\n","    \n","    ## Add args ##\n","    NUM_STAGES = len(NUM_CLASSES)\n","\n","    ## Set random seeds ##\n","    torch.backends.cudnn.deterministic = True\n","    torch.manual_seed(RANDOM_SEED)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(RANDOM_SEED)\n","    np.random.seed(RANDOM_SEED)\n","    random.seed(RANDOM_SEED)\n","    \n","    ## Generate Segmenter ##\n","    segmenter = nn.DataParallel(\n","        create_segmenter(ENC, ENC_PRETRAINED, NUM_CLASSES[0])\n","        ).cuda()\n","\n","    # segmenter = create_segmenter(ENC, ENC_PRETRAINED, NUM_CLASSES[0]).cuda()\n","    logger.info(\" Loaded Segmenter {}, ImageNet-Pre-Trained={}, #PARAMS={:3.2f}M\"\n","                .format(ENC, ENC_PRETRAINED, compute_params(segmenter) / 1e6))\n","    \n","    ## Restore if any ## (at checkpoint)\n","    best_val, epoch_start = load_ckpt(CKPT_PATH, {'segmenter' : segmenter})\n","    \n","    ## Criterion ##\n","    segm_crit = nn.NLLLoss2d(ignore_index=IGNORE_LABEL).cuda()\n","\n","    # ## Saver ##\n","    # saver = Saver(args=vars(args),\n","    #               ckpt_dir=SNAPSHOT_DIR,\n","    #               best_val=best_val,\n","    #               condition=lambda x, y: x > y)  # keep checkpoint with the best validation score\n","\n","    logger.info(\" Training Process Starts\")\n","    for task_idx in range(NUM_STAGES):\n","        start = time.time()\n","        torch.cuda.empty_cache()\n","        ## Create dataloaders ##\n","        train_loader, val_loader = create_loaders(TRAIN_DIR,\n","                                                  VAL_DIR,\n","                                                  TRAIN_LIST[task_idx],\n","                                                  VAL_LIST[task_idx],\n","                                                  SHORTER_SIDE[task_idx],\n","                                                  CROP_SIZE[task_idx],\n","                                                  LOW_SCALE[task_idx],\n","                                                  HIGH_SCALE[task_idx],\n","                                                  NORMALISE_PARAMS,\n","                                                  BATCH_SIZE[task_idx],\n","                                                  NUM_WORKERS,\n","                                                  IGNORE_LABEL)\n","        if EVALUATE:\n","            return validate(segmenter, val_loader, 0, num_classes=NUM_CLASSES[task_idx])\n","\n","        logger.info(\" Training Stage {}\".format(str(task_idx)))\n","        ## Optimisers ##\n","        enc_params = []\n","        dec_params = []\n","        for k,v in segmenter.named_parameters():\n","            if bool(re.match(\".*conv1.*|.*bn1.*|.*layer.*\", k)):\n","                enc_params.append(v)\n","                logger.info(\" Enc. parameter: {}\".format(k))\n","            else:\n","                dec_params.append(v)\n","                logger.info(\" Dec. parameter: {}\".format(k))\n","        optim_enc, optim_dec = create_optimisers(LR_ENC[task_idx], LR_DEC[task_idx],\n","                                                 MOM_ENC[task_idx], MOM_DEC[task_idx],\n","                                                 WD_ENC[task_idx], WD_DEC[task_idx],\n","                                                 enc_params, dec_params, OPTIM_DEC)\n","        for epoch in range(NUM_SEGM_EPOCHS[task_idx]):\n","            train_segmenter(segmenter, train_loader,\n","                            optim_enc, optim_dec,\n","                            epoch_start, segm_crit,\n","                            FREEZE_BN[task_idx])\n","            if (epoch + 1) % (VAL_EVERY[task_idx]) == 0:\n","                miou = validate(segmenter, val_loader, epoch_start, NUM_CLASSES[task_idx])\n","                # saver.save(\n","                #     miou,\n","                #     {'segmenter' : segmenter.state_dict(),\n","                #      'epoch_start' : epoch_start}, logger\n","                #      )\n","            epoch_start += 1\n","            \n","            torch.save(segmenter, \"/content/drive/My Drive/DeepLearningX/models/ResNet/model_res{}_{}_{}\".format(ENC, FREEZED, epoch))\n","\n","        logger.info(\"Stage {} finished, time spent {:.3f}min\".format(\n","            task_idx, (time.time() - start) / 60.))\n","        \n","    # logger.info(\"All stages are now finished. Best Val is {:.3f}\".format(\n","    #     saver.best_val))    \n","\n","# if __name__ == '__main__':\n","#     logging.basicConfig(level=logging.INFO)\n","#     main()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8J04OSQ4LcN_","colab_type":"text"},"source":["## Configurations and training"]},{"cell_type":"code","metadata":{"id":"mw-IF2QlzGXh","colab_type":"code","colab":{}},"source":["# DATASET PARAMETERS\n","TRAIN_DIR = \"/content/drive/My Drive/DeepLearningX/TrainData-People/Train/\"\n","VAL_DIR = \"/content/drive/My Drive/DeepLearningX/TrainData-People/Validation/\"\n","TRAIN_LIST = [\"/content/drive/My Drive/DeepLearningX/TrainData-People/Train/train.txt\"] * 3\n","VAL_LIST = [\"/content/drive/My Drive/DeepLearningX/TrainData-People/Validation/validation.txt\"] * 3\n","SHORTER_SIDE = [350] * 3\n","CROP_SIZE = [500] * 3\n","NORMALISE_PARAMS = [1./255, # SCALE\n","                    np.array([0.485, 0.456, 0.406]).reshape((1, 1, 3)), # MEAN\n","                    np.array([0.229, 0.224, 0.225]).reshape((1, 1, 3))] # STD\n","BATCH_SIZE = [10] * 3\n","NUM_WORKERS = 16\n","NUM_CLASSES = [2] * 3\n","LOW_SCALE = [0.5] * 3\n","HIGH_SCALE = [2.0] * 3\n","IGNORE_LABEL = 255\n","\n","# ENCODER PARAMETERS\n","ENC = '50' # Which model we are training\n","ENC_PRETRAINED = True  # pre-trained on ImageNet or randomly initialised\n","\n","# GENERAL\n","EVALUATE = False\n","FREEZE_BN = [True] * 3\n","NUM_SEGM_EPOCHS = [100] * 3\n","PRINT_EVERY = 100\n","RANDOM_SEED = 42\n","SNAPSHOT_DIR = './ckpt/'\n","CKPT_PATH = './ckpt/checkpoint.pth.tar'\n","VAL_EVERY = [1] * 3 # how often to record validation scores\n","\n","# OPTIMISERS' PARAMETERS\n","LR_ENC = [0] #[5e-4, 2.5e-4, 1e-4]  # TO FREEZE, PUT 0\n","LR_DEC = [5e-3, 2.5e-3, 1e-3]\n","MOM_ENC = [0] #[0.9] * 3 # TO FREEZE, PUT 0\n","MOM_DEC = [0.9] * 3\n","WD_ENC = [0] #[1e-5] * 3 # TO FREEZE, PUT 0\n","WD_DEC = [1e-5] * 3\n","OPTIM_DEC = 'sgd'\n","FREEZED = 'freezed'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8qCo5Ysu_cL","colab_type":"code","outputId":"eca41e3e-c79d-4c39-a411-69012b4b645f","executionInfo":{"status":"error","timestamp":1573408179749,"user_tz":-60,"elapsed":2812015,"user":{"displayName":"Jørgen LUND","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCl34-6f7cAnGnbJZYUpTfImEMzN-NAXzrF8r1_bw=s64","userId":"05384122703626563336"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["main()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:__main__: Loaded Segmenter 50, ImageNet-Pre-Trained=True, #PARAMS=27.31M\n","INFO:__main__: Training Process Starts\n","INFO:__main__: Created train set = 699 examples, val set = 100 examples\n","INFO:__main__: Training Stage 0\n","INFO:__main__: Enc. parameter: module.conv1.weight\n","INFO:__main__: Enc. parameter: module.bn1.weight\n","INFO:__main__: Enc. parameter: module.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer1.0.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer1.0.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer1.0.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer1.0.downsample.0.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.downsample.1.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.downsample.1.bias\n","INFO:__main__: Enc. parameter: module.layer1.1.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer1.1.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer1.1.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer1.2.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer1.2.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer1.2.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer2.0.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer2.0.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer2.0.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer2.0.downsample.0.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.downsample.1.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.downsample.1.bias\n","INFO:__main__: Enc. parameter: module.layer2.1.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer2.1.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer2.1.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer2.2.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer2.2.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer2.2.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer2.3.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer2.3.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer2.3.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.0.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.0.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.0.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.0.downsample.0.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.downsample.1.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.downsample.1.bias\n","INFO:__main__: Enc. parameter: module.layer3.1.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.1.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.1.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.2.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.2.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.2.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.3.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.3.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.3.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.4.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.4.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.4.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.5.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.5.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.5.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer4.0.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer4.0.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer4.0.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer4.0.downsample.0.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.downsample.1.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.downsample.1.bias\n","INFO:__main__: Enc. parameter: module.layer4.1.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer4.1.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer4.1.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer4.2.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer4.2.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer4.2.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn3.bias\n","INFO:__main__: Dec. parameter: module.p_ims1d2_outl1_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_pool.0.1_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_pool.0.2_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_pool.0.3_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_pool.0.4_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_b3_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.p_ims1d2_outl2_dimred.weight\n","INFO:__main__: Dec. parameter: module.adapt_stage2_b2_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_pool.0.1_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_pool.0.2_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_pool.0.3_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_pool.0.4_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_b3_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.p_ims1d2_outl3_dimred.weight\n","INFO:__main__: Dec. parameter: module.adapt_stage3_b2_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_pool.0.1_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_pool.0.2_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_pool.0.3_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_pool.0.4_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_b3_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.p_ims1d2_outl4_dimred.weight\n","INFO:__main__: Dec. parameter: module.adapt_stage4_b2_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g4_pool.0.1_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g4_pool.0.2_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g4_pool.0.3_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g4_pool.0.4_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.clf_conv.weight\n","INFO:__main__: Dec. parameter: module.clf_conv.bias\n","INFO:__main__: Train epoch: 0 [0/69]\tAvg. Loss: 0.642\tAvg. Time: 1.302\n","INFO:__main__: IoUs: [0.77827531 0.19257264]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.485\n","INFO:__main__: Train epoch: 1 [0/69]\tAvg. Loss: 0.576\tAvg. Time: 0.677\n","INFO:__main__: IoUs: [0.80808627 0.50353307]\n","INFO:__main__: Val epoch: 1\tMean IoU: 0.656\n","INFO:__main__: Train epoch: 2 [0/69]\tAvg. Loss: 0.237\tAvg. Time: 0.706\n","INFO:__main__: IoUs: [0.84181711 0.53062721]\n","INFO:__main__: Val epoch: 2\tMean IoU: 0.686\n","INFO:__main__: Train epoch: 3 [0/69]\tAvg. Loss: 0.226\tAvg. Time: 0.656\n","INFO:__main__: IoUs: [0.85526342 0.53582491]\n","INFO:__main__: Val epoch: 3\tMean IoU: 0.696\n","INFO:__main__: Train epoch: 4 [0/69]\tAvg. Loss: 0.199\tAvg. Time: 0.674\n","INFO:__main__: IoUs: [0.84663297 0.55305605]\n","INFO:__main__: Val epoch: 4\tMean IoU: 0.700\n","INFO:__main__: Train epoch: 5 [0/69]\tAvg. Loss: 0.172\tAvg. Time: 0.768\n","INFO:__main__: IoUs: [0.85934348 0.548237  ]\n","INFO:__main__: Val epoch: 5\tMean IoU: 0.704\n","INFO:__main__: Train epoch: 6 [0/69]\tAvg. Loss: 0.184\tAvg. Time: 0.712\n","INFO:__main__: IoUs: [0.85799331 0.55724786]\n","INFO:__main__: Val epoch: 6\tMean IoU: 0.708\n","INFO:__main__: Train epoch: 7 [0/69]\tAvg. Loss: 0.158\tAvg. Time: 0.728\n","INFO:__main__: IoUs: [0.86167195 0.54394867]\n","INFO:__main__: Val epoch: 7\tMean IoU: 0.703\n","INFO:__main__: Train epoch: 8 [0/69]\tAvg. Loss: 0.166\tAvg. Time: 0.541\n","INFO:__main__: IoUs: [0.86441083 0.56355824]\n","INFO:__main__: Val epoch: 8\tMean IoU: 0.714\n","INFO:__main__: Train epoch: 9 [0/69]\tAvg. Loss: 0.131\tAvg. Time: 0.743\n","INFO:__main__: IoUs: [0.86390607 0.54187847]\n","INFO:__main__: Val epoch: 9\tMean IoU: 0.703\n","INFO:__main__: Train epoch: 10 [0/69]\tAvg. Loss: 0.123\tAvg. Time: 0.757\n","INFO:__main__: IoUs: [0.86724719 0.55501826]\n","INFO:__main__: Val epoch: 10\tMean IoU: 0.711\n","INFO:__main__: Train epoch: 11 [0/69]\tAvg. Loss: 0.160\tAvg. Time: 0.522\n","INFO:__main__: IoUs: [0.86686363 0.57933471]\n","INFO:__main__: Val epoch: 11\tMean IoU: 0.723\n","INFO:__main__: Train epoch: 12 [0/69]\tAvg. Loss: 0.082\tAvg. Time: 0.689\n","INFO:__main__: IoUs: [0.86983584 0.57374706]\n","INFO:__main__: Val epoch: 12\tMean IoU: 0.722\n","INFO:__main__: Train epoch: 13 [0/69]\tAvg. Loss: 0.098\tAvg. Time: 0.973\n","INFO:__main__: IoUs: [0.86786418 0.5826938 ]\n","INFO:__main__: Val epoch: 13\tMean IoU: 0.725\n","INFO:__main__: Train epoch: 14 [0/69]\tAvg. Loss: 0.095\tAvg. Time: 0.528\n","INFO:__main__: IoUs: [0.8714328  0.58726116]\n","INFO:__main__: Val epoch: 14\tMean IoU: 0.729\n","INFO:__main__: Train epoch: 15 [0/69]\tAvg. Loss: 0.186\tAvg. Time: 0.700\n","INFO:__main__: IoUs: [0.86998782 0.59574604]\n","INFO:__main__: Val epoch: 15\tMean IoU: 0.733\n","INFO:__main__: Train epoch: 16 [0/69]\tAvg. Loss: 0.161\tAvg. Time: 0.676\n","INFO:__main__: IoUs: [0.87336127 0.59380281]\n","INFO:__main__: Val epoch: 16\tMean IoU: 0.734\n","INFO:__main__: Train epoch: 17 [0/69]\tAvg. Loss: 0.073\tAvg. Time: 0.676\n","INFO:__main__: IoUs: [0.8743209  0.57986206]\n","INFO:__main__: Val epoch: 17\tMean IoU: 0.727\n","INFO:__main__: Train epoch: 18 [0/69]\tAvg. Loss: 0.113\tAvg. Time: 0.866\n","INFO:__main__: IoUs: [0.87345149 0.58416035]\n","INFO:__main__: Val epoch: 18\tMean IoU: 0.729\n","INFO:__main__: Train epoch: 19 [0/69]\tAvg. Loss: 0.136\tAvg. Time: 0.726\n","INFO:__main__: IoUs: [0.87363398 0.59716828]\n","INFO:__main__: Val epoch: 19\tMean IoU: 0.735\n","INFO:__main__: Train epoch: 20 [0/69]\tAvg. Loss: 0.081\tAvg. Time: 0.639\n","INFO:__main__: IoUs: [0.8738789  0.60256666]\n","INFO:__main__: Val epoch: 20\tMean IoU: 0.738\n","INFO:__main__: Train epoch: 21 [0/69]\tAvg. Loss: 0.099\tAvg. Time: 0.650\n","INFO:__main__: IoUs: [0.89622014 0.62598747]\n","INFO:__main__: Val epoch: 21\tMean IoU: 0.761\n","INFO:__main__: Train epoch: 22 [0/69]\tAvg. Loss: 0.085\tAvg. Time: 0.736\n","INFO:__main__: IoUs: [0.8770234  0.59457525]\n","INFO:__main__: Val epoch: 22\tMean IoU: 0.736\n","INFO:__main__: Train epoch: 23 [0/69]\tAvg. Loss: 0.084\tAvg. Time: 0.598\n","INFO:__main__: IoUs: [0.9148128  0.67670858]\n","INFO:__main__: Val epoch: 23\tMean IoU: 0.796\n","INFO:__main__: Train epoch: 24 [0/69]\tAvg. Loss: 0.143\tAvg. Time: 0.542\n","INFO:__main__: IoUs: [0.87646631 0.57829902]\n","INFO:__main__: Val epoch: 24\tMean IoU: 0.727\n","INFO:__main__: Train epoch: 25 [0/69]\tAvg. Loss: 0.077\tAvg. Time: 0.516\n","INFO:__main__: IoUs: [0.89767539 0.63557402]\n","INFO:__main__: Val epoch: 25\tMean IoU: 0.767\n","INFO:__main__: Train epoch: 26 [0/69]\tAvg. Loss: 0.076\tAvg. Time: 0.662\n","INFO:__main__: IoUs: [0.87809587 0.59306023]\n","INFO:__main__: Val epoch: 26\tMean IoU: 0.736\n","INFO:__main__: Train epoch: 27 [0/69]\tAvg. Loss: 0.097\tAvg. Time: 0.724\n","INFO:__main__: IoUs: [0.89643979 0.64293667]\n","INFO:__main__: Val epoch: 27\tMean IoU: 0.770\n","INFO:__main__: Train epoch: 28 [0/69]\tAvg. Loss: 0.130\tAvg. Time: 0.579\n","INFO:__main__: IoUs: [0.87841821 0.59185162]\n","INFO:__main__: Val epoch: 28\tMean IoU: 0.735\n","INFO:__main__: Train epoch: 29 [0/69]\tAvg. Loss: 0.081\tAvg. Time: 0.665\n","INFO:__main__: IoUs: [0.91769679 0.68663133]\n","INFO:__main__: Val epoch: 29\tMean IoU: 0.802\n","INFO:__main__: Train epoch: 30 [0/69]\tAvg. Loss: 0.100\tAvg. Time: 0.722\n","INFO:__main__: IoUs: [0.90060507 0.64170011]\n","INFO:__main__: Val epoch: 30\tMean IoU: 0.771\n","INFO:__main__: Train epoch: 31 [0/69]\tAvg. Loss: 0.089\tAvg. Time: 0.706\n","INFO:__main__: IoUs: [0.91868557 0.68700705]\n","INFO:__main__: Val epoch: 31\tMean IoU: 0.803\n","INFO:__main__: Train epoch: 32 [0/69]\tAvg. Loss: 0.099\tAvg. Time: 0.730\n","INFO:__main__: IoUs: [0.88031025 0.59616841]\n","INFO:__main__: Val epoch: 32\tMean IoU: 0.738\n","INFO:__main__: Train epoch: 33 [0/69]\tAvg. Loss: 0.087\tAvg. Time: 0.754\n","INFO:__main__: IoUs: [0.90076449 0.64704742]\n","INFO:__main__: Val epoch: 33\tMean IoU: 0.774\n","INFO:__main__: Train epoch: 34 [0/69]\tAvg. Loss: 0.108\tAvg. Time: 0.691\n","INFO:__main__: IoUs: [0.90199039 0.64435837]\n","INFO:__main__: Val epoch: 34\tMean IoU: 0.773\n","INFO:__main__: Train epoch: 35 [0/69]\tAvg. Loss: 0.056\tAvg. Time: 0.604\n","INFO:__main__: IoUs: [0.90261051 0.64613065]\n","INFO:__main__: Val epoch: 35\tMean IoU: 0.774\n","INFO:__main__: Train epoch: 36 [0/69]\tAvg. Loss: 0.075\tAvg. Time: 0.646\n","INFO:__main__: IoUs: [0.89998643 0.63273154]\n","INFO:__main__: Val epoch: 36\tMean IoU: 0.766\n","INFO:__main__: Train epoch: 37 [0/69]\tAvg. Loss: 0.057\tAvg. Time: 0.741\n","INFO:__main__: IoUs: [0.90103788 0.62964227]\n","INFO:__main__: Val epoch: 37\tMean IoU: 0.765\n","INFO:__main__: Train epoch: 38 [0/69]\tAvg. Loss: 0.037\tAvg. Time: 0.733\n","INFO:__main__: IoUs: [0.90097117 0.64289563]\n","INFO:__main__: Val epoch: 38\tMean IoU: 0.772\n","INFO:__main__: Train epoch: 39 [0/69]\tAvg. Loss: 0.061\tAvg. Time: 0.597\n","INFO:__main__: IoUs: [0.89927474 0.65074136]\n","INFO:__main__: Val epoch: 39\tMean IoU: 0.775\n","INFO:__main__: Train epoch: 40 [0/69]\tAvg. Loss: 0.082\tAvg. Time: 0.713\n","INFO:__main__: IoUs: [0.90038401 0.62555317]\n","INFO:__main__: Val epoch: 40\tMean IoU: 0.763\n","INFO:__main__: Train epoch: 41 [0/69]\tAvg. Loss: 0.068\tAvg. Time: 0.716\n","INFO:__main__: IoUs: [0.9010776  0.63757843]\n","INFO:__main__: Val epoch: 41\tMean IoU: 0.769\n","INFO:__main__: Train epoch: 42 [0/69]\tAvg. Loss: 0.081\tAvg. Time: 0.736\n","INFO:__main__: IoUs: [0.90356781 0.64110181]\n","INFO:__main__: Val epoch: 42\tMean IoU: 0.772\n","INFO:__main__: Train epoch: 43 [0/69]\tAvg. Loss: 0.073\tAvg. Time: 0.700\n","INFO:__main__: IoUs: [0.90317222 0.65077821]\n","INFO:__main__: Val epoch: 43\tMean IoU: 0.777\n","INFO:__main__: Train epoch: 44 [0/69]\tAvg. Loss: 0.074\tAvg. Time: 0.619\n","INFO:__main__: IoUs: [0.87907252 0.58943563]\n","INFO:__main__: Val epoch: 44\tMean IoU: 0.734\n","INFO:__main__: Train epoch: 45 [0/69]\tAvg. Loss: 0.100\tAvg. Time: 0.866\n","INFO:__main__: IoUs: [0.90163332 0.63300545]\n","INFO:__main__: Val epoch: 45\tMean IoU: 0.767\n","INFO:__main__: Train epoch: 46 [0/69]\tAvg. Loss: 0.096\tAvg. Time: 0.628\n","INFO:__main__: IoUs: [0.90169527 0.6508106 ]\n","INFO:__main__: Val epoch: 46\tMean IoU: 0.776\n","INFO:__main__: Train epoch: 47 [0/69]\tAvg. Loss: 0.098\tAvg. Time: 0.721\n","INFO:__main__: IoUs: [0.90262387 0.64707295]\n","INFO:__main__: Val epoch: 47\tMean IoU: 0.775\n","INFO:__main__: Train epoch: 48 [0/69]\tAvg. Loss: 0.072\tAvg. Time: 0.804\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-2f974c67f82c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    325\u001b[0m                             \u001b[0moptim_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_dec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                             \u001b[0mepoch_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegm_crit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                             FREEZE_BN[task_idx])\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVAL_EVERY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mmiou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-2f974c67f82c>\u001b[0m in \u001b[0;36mtrain_segmenter\u001b[0;34m(segmenter, train_loader, optim_enc, optim_dec, epoch, segm_crit, freeze_bn)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0moptim_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0moptim_dec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mbatch_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0mparam_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}