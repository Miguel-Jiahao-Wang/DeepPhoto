{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"50UNFREEZE.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"McVe-l3nKJqL","colab_type":"text"},"source":["# Training using unfreezed Resnet50 as backbone"]},{"cell_type":"markdown","metadata":{"id":"ZxSXZ32SKxpU","colab_type":"text"},"source":["## Setup and imports"]},{"cell_type":"code","metadata":{"id":"UYKGBH4-31uu","colab_type":"code","outputId":"da661b61-5c14-4392-ef14-ad6b6e5b4a43","executionInfo":{"status":"ok","timestamp":1573407044432,"user_tz":-60,"elapsed":23882,"user":{"displayName":"Jørgen LUND","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCl34-6f7cAnGnbJZYUpTfImEMzN-NAXzrF8r1_bw=s64","userId":"05384122703626563336"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s77TdXYH5Yf5","colab_type":"code","outputId":"c2a75161-1b45-4abc-b215-2ba96c8b1fe7","executionInfo":{"status":"ok","timestamp":1573407045753,"user_tz":-60,"elapsed":1302,"user":{"displayName":"Jørgen LUND","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCl34-6f7cAnGnbJZYUpTfImEMzN-NAXzrF8r1_bw=s64","userId":"05384122703626563336"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/DeepLearningX/gitclone/light-weight-refinenet/src"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/DeepLearningX/gitclone/light-weight-refinenet/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C-X2w5mCvJv1","colab_type":"code","colab":{}},"source":["# general libs\n","import argparse\n","import logging\n","import os\n","import random\n","import re\n","import sys\n","import time\n","\n","# misc\n","import cv2\n","import numpy as np\n","\n","# pytorch libs\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import confusion_matrix\n","\n","# custom libs\n","from util import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IMiVCWtWKz7-","colab_type":"text"},"source":["## Methods for training"]},{"cell_type":"code","metadata":{"id":"UIIwnxyc-ma8","colab_type":"code","colab":{}},"source":["# defining methods for training\n","sys.path.append(\"..\")\n","\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, random_split\n","# Custom libraries\n","from datasets import NYUDataset as Dataset\n","from datasets import Pad, RandomCrop, RandomMirror, ResizeShorterScale, ToTensor, Normalise\n","\n","def create_segmenter(\n","    net, pretrained, num_classes\n","    ):\n","    \"\"\"Create Encoder; for now only ResNet [50,101,152]\"\"\"\n","    from models.resnet import rf_lw50, rf_lw101, rf_lw152\n","    if str(net) == '50':\n","        return rf_lw50(num_classes, imagenet=pretrained)\n","    elif str(net) == '101':\n","        return rf_lw101(num_classes, imagenet=pretrained)\n","    elif str(net) == '152':\n","        return rf_lw152(num_classes, imagenet=pretrained)\n","    elif str(net) == 'Mob':\n","        return mbv2(num_classes, pretrained=pretrained)\n","    else:\n","        raise ValueError(\"{} is not supported\".format(str(net)))\n","\n","def create_loaders(\n","    train_dir, val_dir, train_list, val_list,\n","    shorter_side, crop_size, low_scale, high_scale,\n","    normalise_params, batch_size, num_workers, ignore_label\n","    ):\n","    \"\"\"\n","    Args:\n","      train_dir (str) : path to the root directory of the training set.\n","      val_dir (str) : path to the root directory of the validation set.\n","      train_list (str) : path to the training list.\n","      val_list (str) : path to the validation list.\n","      shorter_side (int) : parameter of the shorter_side resize transformation.\n","      crop_size (int) : square crop to apply during the training.\n","      low_scale (float) : lowest scale ratio for augmentations.\n","      high_scale (float) : highest scale ratio for augmentations.\n","      normalise_params (list / tuple) : img_scale, img_mean, img_std.\n","      batch_size (int) : training batch size.\n","      num_workers (int) : number of workers to parallelise data loading operations.\n","      ignore_label (int) : label to pad segmentation masks with\n","\n","    Returns:\n","      train_loader, val loader\n","\n","    \"\"\"\n","\n","    ## Transformations during training ##\n","    composed_trn = transforms.Compose([ResizeShorterScale(shorter_side, low_scale, high_scale),\n","                                    Pad(crop_size, [123.675, 116.28 , 103.53], ignore_label),\n","                                    RandomMirror(),\n","                                    RandomCrop(crop_size),\n","                                    Normalise(*normalise_params),\n","                                    ToTensor()])\n","    composed_val = transforms.Compose([Normalise(*normalise_params),\n","                                    ToTensor()])\n","    ## Training and validation sets ##\n","    trainset = Dataset(data_file=train_list,\n","                       data_dir=train_dir,\n","                       transform_trn=composed_trn,\n","                       transform_val=composed_val)\n","\n","    valset = Dataset(data_file=val_list,\n","                         data_dir=val_dir,\n","                         transform_trn=None,\n","                         transform_val=composed_val)\n","    logger.info(\" Created train set = {} examples, val set = {} examples\"\n","                .format(len(trainset), len(valset)))\n","    ## Training and validation loaders ##\n","    train_loader = DataLoader(trainset,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=num_workers,\n","                              pin_memory=True,\n","                              drop_last=True)\n","    val_loader = DataLoader(valset,\n","                            batch_size=1,\n","                            shuffle=False,\n","                            num_workers=num_workers,\n","                            pin_memory=True)\n","    return train_loader, val_loader\n","\n","def create_optimisers(\n","    lr_enc, lr_dec,\n","    mom_enc, mom_dec,\n","    wd_enc, wd_dec,\n","    param_enc, param_dec,\n","    optim_dec\n","    ):\n","    \"\"\"Create optimisers for encoder, decoder and controller\"\"\"\n","    optim_enc = torch.optim.SGD(param_enc, lr=lr_enc, momentum=mom_enc,\n","                                weight_decay=wd_enc)\n","    if optim_dec == 'sgd':\n","        optim_dec = torch.optim.SGD(param_dec, lr=lr_dec,\n","                                    momentum=mom_dec, weight_decay=wd_dec)\n","    elif optim_dec == 'adam':\n","        optim_dec = torch.optim.Adam(param_dec, lr=lr_dec, weight_decay=wd_dec, eps=1e-3)\n","    return optim_enc, optim_dec\n","\n","def load_ckpt(\n","    ckpt_path, ckpt_dict\n","    ):\n","    best_val = epoch_start = 0\n","    if os.path.exists(CKPT_PATH):\n","        ckpt = torch.load(ckpt_path)\n","        for (k, v) in ckpt_dict.items():\n","            if k in ckpt:\n","                v.load_state_dict(ckpt[k])\n","        best_val = ckpt.get('best_val', 0)\n","        epoch_start = ckpt.get('epoch_start', 0)\n","        logger.info(\" Found checkpoint at {} with best_val {:.4f} at epoch {}\".\n","            format(\n","                ckpt_path, best_val, epoch_start\n","            ))\n","    return best_val, epoch_start\n","\n","def train_segmenter(\n","    segmenter, train_loader, optim_enc, optim_dec,\n","    epoch, segm_crit, freeze_bn\n","    ):\n","    \"\"\"Training segmenter\n","\n","    Args:\n","      segmenter (nn.Module) : segmentation network\n","      train_loader (DataLoader) : training data iterator\n","      optim_enc (optim) : optimiser for encoder\n","      optim_dec (optim) : optimiser for decoder\n","      epoch (int) : current epoch\n","      segm_crit (nn.Loss) : segmentation criterion\n","      freeze_bn (bool) : whether to keep BN params intact\n","\n","    \"\"\"\n","    train_loader.dataset.set_stage('train')\n","    segmenter.train()\n","    if freeze_bn:\n","        for m in segmenter.modules():\n","            if isinstance(m, nn.BatchNorm2d):\n","                m.eval()\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    for i, sample in enumerate(train_loader):\n","        start = time.time()\n","        input = sample['image'].cuda()\n","        target = sample['mask'].cuda()\n","        input_var = torch.autograd.Variable(input).float()\n","        target_var = torch.autograd.Variable(target).long()\n","        # Compute output\n","        output = segmenter(input_var)\n","        output = nn.functional.interpolate(output, size=target_var.size()[1:], mode='bilinear', align_corners=False)\n","        soft_output = nn.LogSoftmax()(output)\n","        # Compute loss and backpropagate\n","        loss = segm_crit(soft_output, target_var)\n","        optim_enc.zero_grad()\n","        optim_dec.zero_grad()\n","        loss.backward()\n","        optim_enc.step()\n","        optim_dec.step()\n","        losses.update(loss.item())\n","        batch_time.update(time.time() - start)\n","        if i % PRINT_EVERY == 0:\n","            logger.info(' Train epoch: {} [{}/{}]\\t'\n","                        'Avg. Loss: {:.3f}\\t'\n","                        'Avg. Time: {:.3f}'.format(\n","                            epoch, i, len(train_loader),\n","                            losses.avg, batch_time.avg\n","                        ))\n","def compute_iu(cm):\n","    \"\"\"Compute IU from confusion matrix.\n","\n","    Args:\n","      cm (Tensor) : square confusion matrix.\n","\n","    Returns:\n","      IU vector (Tensor).\n","\n","    \"\"\"\n","    pi = 0\n","    gi = 0\n","    ii = 0\n","    denom = 0\n","    n_classes = cm.shape[0]\n","    IU = np.ones(n_classes)\n","    \n","    for i in range(n_classes):\n","        pi = sum(cm[:, i])\n","        gi = sum(cm[i, :])\n","        ii = cm[i, i]\n","        denom = pi + gi - ii\n","        if denom > 0:\n","            IU[i] = ii / denom\n","    return IU\n","\n","def validate(\n","    segmenter, val_loader, epoch, num_classes=-1\n","    ):\n","    \"\"\"Validate segmenter\n","\n","    Args:\n","      segmenter (nn.Module) : segmentation network\n","      val_loader (DataLoader) : training data iterator\n","      epoch (int) : current epoch\n","      num_classes (int) : number of classes to consider\n","\n","    Returns:\n","      Mean IoU (float)\n","    \"\"\"\n","    val_loader.dataset.set_stage('val')\n","    segmenter.eval()\n","    cm = np.zeros((num_classes, num_classes), dtype=int)\n","    with torch.no_grad():\n","        for i, sample in enumerate(val_loader):\n","            start = time.time()\n","            input = sample['image']\n","            target = sample['mask']\n","            input_var = torch.autograd.Variable(input).float().cuda()\n","            # Compute output\n","            output = segmenter(input_var)\n","            output = cv2.resize(output[0, :num_classes].data.cpu().numpy().transpose(1, 2, 0),\n","                                target.size()[1:][::-1],\n","                                interpolation=cv2.INTER_CUBIC).argmax(axis=2).astype(np.uint8)\n","            # Compute IoU\n","            gt = target[0].data.cpu().numpy().astype(np.uint8)\n","            gt_idx = gt < num_classes # Ignore every class index larger than the number of classes\n","            cm += confusion_matrix(output[gt_idx], gt[gt_idx])\n","\n","            # if i % PRINT_EVERY == 0:\n","            #     logger.info(' Val epoch: {} [{}/{}]\\t'\n","            #                 'Mean IoU: {:.3f}'.format(\n","            #                     epoch, i, len(val_loader),\n","            #                     compute_iu(cm).mean()\n","            #                 ))\n","\n","    ious = compute_iu(cm)\n","    logger.info(\" IoUs: {}\".format(ious))\n","    miou = np.mean(ious)\n","\n","    miou_path = '/content/drive/My Drive/DeepLearningX/models/ResNet/mious_res{}_{}.txt'.format(ENC, FREEZED)\n","\n","    with open(miou_path, 'a') as f:\n","      f.write(\"{}\\n\".format(miou))\n","\n","    logger.info(' Val epoch: {}\\tMean IoU: {:.3f}'.format(\n","                                epoch, miou))\n","    return miou\n","\n","def main():\n","    logging.basicConfig(level=logging.INFO)\n","    global logger #, args\n","    # args = get_arguments()\n","    logger = logging.getLogger(__name__)\n","    \n","    ## Add args ##\n","    NUM_STAGES = len(NUM_CLASSES)\n","\n","    ## Set random seeds ##\n","    torch.backends.cudnn.deterministic = True\n","    torch.manual_seed(RANDOM_SEED)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(RANDOM_SEED)\n","    np.random.seed(RANDOM_SEED)\n","    random.seed(RANDOM_SEED)\n","    \n","    ## Generate Segmenter ##\n","    segmenter = nn.DataParallel(\n","        create_segmenter(ENC, ENC_PRETRAINED, NUM_CLASSES[0])\n","        ).cuda()\n","\n","    # segmenter = create_segmenter(ENC, ENC_PRETRAINED, NUM_CLASSES[0]).cuda()\n","    logger.info(\" Loaded Segmenter {}, ImageNet-Pre-Trained={}, #PARAMS={:3.2f}M\"\n","                .format(ENC, ENC_PRETRAINED, compute_params(segmenter) / 1e6))\n","    \n","    ## Restore if any ## (at checkpoint)\n","    best_val, epoch_start = load_ckpt(CKPT_PATH, {'segmenter' : segmenter})\n","    \n","    ## Criterion ##\n","    segm_crit = nn.NLLLoss2d(ignore_index=IGNORE_LABEL).cuda()\n","\n","    # ## Saver ##\n","    # saver = Saver(args=vars(args),\n","    #               ckpt_dir=SNAPSHOT_DIR,\n","    #               best_val=best_val,\n","    #               condition=lambda x, y: x > y)  # keep checkpoint with the best validation score\n","\n","    logger.info(\" Training Process Starts\")\n","    for task_idx in range(NUM_STAGES):\n","        start = time.time()\n","        torch.cuda.empty_cache()\n","        ## Create dataloaders ##\n","        train_loader, val_loader = create_loaders(TRAIN_DIR,\n","                                                  VAL_DIR,\n","                                                  TRAIN_LIST[task_idx],\n","                                                  VAL_LIST[task_idx],\n","                                                  SHORTER_SIDE[task_idx],\n","                                                  CROP_SIZE[task_idx],\n","                                                  LOW_SCALE[task_idx],\n","                                                  HIGH_SCALE[task_idx],\n","                                                  NORMALISE_PARAMS,\n","                                                  BATCH_SIZE[task_idx],\n","                                                  NUM_WORKERS,\n","                                                  IGNORE_LABEL)\n","        if EVALUATE:\n","            return validate(segmenter, val_loader, 0, num_classes=NUM_CLASSES[task_idx])\n","\n","        logger.info(\" Training Stage {}\".format(str(task_idx)))\n","        ## Optimisers ##\n","        enc_params = []\n","        dec_params = []\n","        for k,v in segmenter.named_parameters():\n","            if bool(re.match(\".*conv1.*|.*bn1.*|.*layer.*\", k)):\n","                enc_params.append(v)\n","                logger.info(\" Enc. parameter: {}\".format(k))\n","            else:\n","                dec_params.append(v)\n","                logger.info(\" Dec. parameter: {}\".format(k))\n","        optim_enc, optim_dec = create_optimisers(LR_ENC[task_idx], LR_DEC[task_idx],\n","                                                 MOM_ENC[task_idx], MOM_DEC[task_idx],\n","                                                 WD_ENC[task_idx], WD_DEC[task_idx],\n","                                                 enc_params, dec_params, OPTIM_DEC)\n","        for epoch in range(NUM_SEGM_EPOCHS[task_idx]):\n","            train_segmenter(segmenter, train_loader,\n","                            optim_enc, optim_dec,\n","                            epoch_start, segm_crit,\n","                            FREEZE_BN[task_idx])\n","            if (epoch + 1) % (VAL_EVERY[task_idx]) == 0:\n","                miou = validate(segmenter, val_loader, epoch_start, NUM_CLASSES[task_idx])\n","                # saver.save(\n","                #     miou,\n","                #     {'segmenter' : segmenter.state_dict(),\n","                #      'epoch_start' : epoch_start}, logger\n","                #      )\n","            epoch_start += 1\n","            \n","            torch.save(segmenter, \"/content/drive/My Drive/DeepLearningX/models/ResNet/model_res{}_{}_{}\".format(ENC, FREEZED, epoch))\n","\n","        logger.info(\"Stage {} finished, time spent {:.3f}min\".format(\n","            task_idx, (time.time() - start) / 60.))\n","        \n","    # logger.info(\"All stages are now finished. Best Val is {:.3f}\".format(\n","    #     saver.best_val))    \n","\n","# if __name__ == '__main__':\n","#     logging.basicConfig(level=logging.INFO)\n","#     main()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HMBXB2BK5TA","colab_type":"text"},"source":["## Configurations and training"]},{"cell_type":"code","metadata":{"id":"mw-IF2QlzGXh","colab_type":"code","colab":{}},"source":["# DATASET PARAMETERS\n","TRAIN_DIR = \"/content/drive/My Drive/DeepLearningX/TrainData-People/Train/\"\n","VAL_DIR = \"/content/drive/My Drive/DeepLearningX/TrainData-People/Validation/\"\n","TRAIN_LIST = [\"/content/drive/My Drive/DeepLearningX/TrainData-People/Train/train.txt\"] * 3\n","VAL_LIST = [\"/content/drive/My Drive/DeepLearningX/TrainData-People/Validation/validation.txt\"] * 3\n","SHORTER_SIDE = [350] * 3\n","CROP_SIZE = [500] * 3\n","NORMALISE_PARAMS = [1./255, # SCALE\n","                    np.array([0.485, 0.456, 0.406]).reshape((1, 1, 3)), # MEAN\n","                    np.array([0.229, 0.224, 0.225]).reshape((1, 1, 3))] # STD\n","BATCH_SIZE = [10] * 3\n","NUM_WORKERS = 16\n","NUM_CLASSES = [2] * 3\n","LOW_SCALE = [0.5] * 3\n","HIGH_SCALE = [2.0] * 3\n","IGNORE_LABEL = 255\n","\n","# ENCODER PARAMETERS\n","ENC = '50' # Which model we are training\n","ENC_PRETRAINED = True  # pre-trained on ImageNet or randomly initialised\n","\n","# GENERAL\n","EVALUATE = False\n","FREEZE_BN = [True] * 3\n","NUM_SEGM_EPOCHS = [100] * 3\n","PRINT_EVERY = 100\n","RANDOM_SEED = 42\n","SNAPSHOT_DIR = './ckpt/'\n","CKPT_PATH = './ckpt/checkpoint.pth.tar'\n","VAL_EVERY = [1] * 3 # how often to record validation scores\n","\n","# OPTIMISERS' PARAMETERS\n","LR_ENC = [5e-4, 2.5e-4, 1e-4]  # TO FREEZE, PUT 0\n","LR_DEC = [5e-3, 2.5e-3, 1e-3]\n","MOM_ENC = [0.9] * 3 # TO FREEZE, PUT 0\n","MOM_DEC = [0.9] * 3\n","WD_ENC = [1e-5] * 3 # TO FREEZE, PUT 0\n","WD_DEC = [1e-5] * 3\n","OPTIM_DEC = 'sgd'\n","FREEZED = 'unfreezed'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8qCo5Ysu_cL","colab_type":"code","outputId":"0a93b020-6b99-4260-bb4d-86fa1915b1f0","executionInfo":{"status":"ok","timestamp":1573398722193,"user_tz":-60,"elapsed":418056,"user":{"displayName":"Jørgen LUND","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCl34-6f7cAnGnbJZYUpTfImEMzN-NAXzrF8r1_bw=s64","userId":"05384122703626563336"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["main()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/50_imagenet.pth.tar\n","INFO:__main__: Loaded Segmenter 50, ImageNet-Pre-Trained=True, #PARAMS=27.31M\n","INFO:__main__: Training Process Starts\n","INFO:__main__: Created train set = 699 examples, val set = 100 examples\n","INFO:__main__: Training Stage 0\n","INFO:__main__: Enc. parameter: module.conv1.weight\n","INFO:__main__: Enc. parameter: module.bn1.weight\n","INFO:__main__: Enc. parameter: module.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer1.0.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer1.0.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer1.0.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer1.0.downsample.0.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.downsample.1.weight\n","INFO:__main__: Enc. parameter: module.layer1.0.downsample.1.bias\n","INFO:__main__: Enc. parameter: module.layer1.1.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer1.1.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer1.1.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer1.1.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer1.2.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer1.2.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer1.2.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer1.2.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer2.0.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer2.0.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer2.0.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer2.0.downsample.0.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.downsample.1.weight\n","INFO:__main__: Enc. parameter: module.layer2.0.downsample.1.bias\n","INFO:__main__: Enc. parameter: module.layer2.1.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer2.1.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer2.1.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer2.1.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer2.2.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer2.2.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer2.2.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer2.2.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer2.3.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer2.3.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer2.3.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer2.3.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.0.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.0.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.0.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.0.downsample.0.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.downsample.1.weight\n","INFO:__main__: Enc. parameter: module.layer3.0.downsample.1.bias\n","INFO:__main__: Enc. parameter: module.layer3.1.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.1.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.1.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.1.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.2.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.2.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.2.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.2.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.3.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.3.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.3.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.3.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.4.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.4.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.4.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.4.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer3.5.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer3.5.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer3.5.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer3.5.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer4.0.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer4.0.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer4.0.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer4.0.downsample.0.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.downsample.1.weight\n","INFO:__main__: Enc. parameter: module.layer4.0.downsample.1.bias\n","INFO:__main__: Enc. parameter: module.layer4.1.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer4.1.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer4.1.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer4.1.bn3.bias\n","INFO:__main__: Enc. parameter: module.layer4.2.conv1.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn1.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn1.bias\n","INFO:__main__: Enc. parameter: module.layer4.2.conv2.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn2.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn2.bias\n","INFO:__main__: Enc. parameter: module.layer4.2.conv3.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn3.weight\n","INFO:__main__: Enc. parameter: module.layer4.2.bn3.bias\n","INFO:__main__: Dec. parameter: module.p_ims1d2_outl1_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_pool.0.1_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_pool.0.2_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_pool.0.3_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_pool.0.4_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g1_b3_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.p_ims1d2_outl2_dimred.weight\n","INFO:__main__: Dec. parameter: module.adapt_stage2_b2_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_pool.0.1_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_pool.0.2_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_pool.0.3_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_pool.0.4_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g2_b3_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.p_ims1d2_outl3_dimred.weight\n","INFO:__main__: Dec. parameter: module.adapt_stage3_b2_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_pool.0.1_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_pool.0.2_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_pool.0.3_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_pool.0.4_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g3_b3_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.p_ims1d2_outl4_dimred.weight\n","INFO:__main__: Dec. parameter: module.adapt_stage4_b2_joint_varout_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g4_pool.0.1_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g4_pool.0.2_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g4_pool.0.3_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.mflow_conv_g4_pool.0.4_outvar_dimred.weight\n","INFO:__main__: Dec. parameter: module.clf_conv.weight\n","INFO:__main__: Dec. parameter: module.clf_conv.bias\n","INFO:__main__: Train epoch: 0 [0/69]\tAvg. Loss: 0.642\tAvg. Time: 2.373\n","INFO:__main__: IoUs: [0.8092548 0.4933086]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.651\n","INFO:__main__: Train epoch: 1 [0/69]\tAvg. Loss: 0.195\tAvg. Time: 2.339\n","INFO:__main__: IoUs: [0.81868358 0.52886353]\n","INFO:__main__: Val epoch: 1\tMean IoU: 0.674\n","INFO:__main__: Train epoch: 2 [0/69]\tAvg. Loss: 0.232\tAvg. Time: 2.387\n","INFO:__main__: IoUs: [0.84108526 0.55847692]\n","INFO:__main__: Val epoch: 2\tMean IoU: 0.700\n","INFO:__main__: Train epoch: 3 [0/69]\tAvg. Loss: 0.192\tAvg. Time: 2.413\n","INFO:__main__: IoUs: [0.86133791 0.57164872]\n","INFO:__main__: Val epoch: 3\tMean IoU: 0.716\n","INFO:__main__: Train epoch: 4 [0/69]\tAvg. Loss: 0.162\tAvg. Time: 2.307\n","INFO:__main__: IoUs: [0.86632722 0.5667709 ]\n","INFO:__main__: Val epoch: 4\tMean IoU: 0.717\n","INFO:__main__: Train epoch: 5 [0/69]\tAvg. Loss: 0.134\tAvg. Time: 2.322\n","INFO:__main__: IoUs: [0.86459919 0.59247047]\n","INFO:__main__: Val epoch: 5\tMean IoU: 0.729\n","INFO:__main__: Train epoch: 6 [0/69]\tAvg. Loss: 0.137\tAvg. Time: 2.375\n","INFO:__main__: IoUs: [0.84220699 0.57156616]\n","INFO:__main__: Val epoch: 6\tMean IoU: 0.707\n","INFO:__main__: Train epoch: 7 [0/69]\tAvg. Loss: 0.174\tAvg. Time: 2.333\n","INFO:__main__: IoUs: [0.89069    0.63001622]\n","INFO:__main__: Val epoch: 7\tMean IoU: 0.760\n","INFO:__main__: Train epoch: 8 [0/69]\tAvg. Loss: 0.140\tAvg. Time: 2.340\n","INFO:__main__: IoUs: [0.88800708 0.62877801]\n","INFO:__main__: Val epoch: 8\tMean IoU: 0.758\n","INFO:__main__: Train epoch: 9 [0/69]\tAvg. Loss: 0.105\tAvg. Time: 2.419\n","INFO:__main__: IoUs: [0.8953941  0.63367196]\n","INFO:__main__: Val epoch: 9\tMean IoU: 0.765\n","INFO:__main__: Train epoch: 10 [0/69]\tAvg. Loss: 0.091\tAvg. Time: 2.329\n","INFO:__main__: IoUs: [0.89574754 0.63240451]\n","INFO:__main__: Val epoch: 10\tMean IoU: 0.764\n","INFO:__main__: Train epoch: 11 [0/69]\tAvg. Loss: 0.126\tAvg. Time: 2.431\n","INFO:__main__: IoUs: [0.90779213 0.66894329]\n","INFO:__main__: Val epoch: 11\tMean IoU: 0.788\n","INFO:__main__: Train epoch: 12 [0/69]\tAvg. Loss: 0.071\tAvg. Time: 2.402\n","INFO:__main__: IoUs: [0.89471331 0.6434568 ]\n","INFO:__main__: Val epoch: 12\tMean IoU: 0.769\n","INFO:__main__: Train epoch: 13 [0/69]\tAvg. Loss: 0.073\tAvg. Time: 2.414\n","INFO:__main__: IoUs: [0.89691679 0.6353096 ]\n","INFO:__main__: Val epoch: 13\tMean IoU: 0.766\n","INFO:__main__: Train epoch: 14 [0/69]\tAvg. Loss: 0.087\tAvg. Time: 2.389\n","INFO:__main__: IoUs: [0.8950787  0.63977237]\n","INFO:__main__: Val epoch: 14\tMean IoU: 0.767\n","INFO:__main__: Train epoch: 15 [0/69]\tAvg. Loss: 0.115\tAvg. Time: 2.391\n","INFO:__main__: IoUs: [0.8979244  0.64000319]\n","INFO:__main__: Val epoch: 15\tMean IoU: 0.769\n","INFO:__main__: Train epoch: 16 [0/69]\tAvg. Loss: 0.127\tAvg. Time: 2.399\n","INFO:__main__: IoUs: [0.9000105  0.63892843]\n","INFO:__main__: Val epoch: 16\tMean IoU: 0.769\n","INFO:__main__: Train epoch: 17 [0/69]\tAvg. Loss: 0.068\tAvg. Time: 2.428\n","INFO:__main__: IoUs: [0.9011596 0.6520681]\n","INFO:__main__: Val epoch: 17\tMean IoU: 0.777\n","INFO:__main__: Train epoch: 18 [0/69]\tAvg. Loss: 0.085\tAvg. Time: 2.437\n","INFO:__main__: IoUs: [0.89883689 0.65425334]\n","INFO:__main__: Val epoch: 18\tMean IoU: 0.777\n","INFO:__main__: Train epoch: 19 [0/69]\tAvg. Loss: 0.106\tAvg. Time: 2.432\n","INFO:__main__: IoUs: [0.89902854 0.64917405]\n","INFO:__main__: Val epoch: 19\tMean IoU: 0.774\n","INFO:__main__: Train epoch: 20 [0/69]\tAvg. Loss: 0.079\tAvg. Time: 2.327\n","INFO:__main__: IoUs: [0.90110837 0.64826166]\n","INFO:__main__: Val epoch: 20\tMean IoU: 0.775\n","INFO:__main__: Train epoch: 21 [0/69]\tAvg. Loss: 0.079\tAvg. Time: 2.363\n","INFO:__main__: IoUs: [0.90242259 0.64744787]\n","INFO:__main__: Val epoch: 21\tMean IoU: 0.775\n","INFO:__main__: Train epoch: 22 [0/69]\tAvg. Loss: 0.061\tAvg. Time: 2.377\n","INFO:__main__: IoUs: [0.90080889 0.65575583]\n","INFO:__main__: Val epoch: 22\tMean IoU: 0.778\n","INFO:__main__: Train epoch: 23 [0/69]\tAvg. Loss: 0.066\tAvg. Time: 2.366\n","INFO:__main__: IoUs: [0.92013911 0.70242266]\n","INFO:__main__: Val epoch: 23\tMean IoU: 0.811\n","INFO:__main__: Train epoch: 24 [0/69]\tAvg. Loss: 0.098\tAvg. Time: 2.373\n","INFO:__main__: IoUs: [0.904323   0.65785029]\n","INFO:__main__: Val epoch: 24\tMean IoU: 0.781\n","INFO:__main__: Train epoch: 25 [0/69]\tAvg. Loss: 0.065\tAvg. Time: 2.414\n","INFO:__main__: IoUs: [0.90046087 0.64619329]\n","INFO:__main__: Val epoch: 25\tMean IoU: 0.773\n","INFO:__main__: Train epoch: 26 [0/69]\tAvg. Loss: 0.074\tAvg. Time: 2.352\n","INFO:__main__: IoUs: [0.90297672 0.64520492]\n","INFO:__main__: Val epoch: 26\tMean IoU: 0.774\n","INFO:__main__: Train epoch: 27 [0/69]\tAvg. Loss: 0.080\tAvg. Time: 2.571\n","INFO:__main__: IoUs: [0.88297968 0.6107802 ]\n","INFO:__main__: Val epoch: 27\tMean IoU: 0.747\n","INFO:__main__: Train epoch: 28 [0/69]\tAvg. Loss: 0.124\tAvg. Time: 2.355\n","INFO:__main__: IoUs: [0.90248314 0.64037483]\n","INFO:__main__: Val epoch: 28\tMean IoU: 0.771\n","INFO:__main__: Train epoch: 29 [0/69]\tAvg. Loss: 0.062\tAvg. Time: 2.420\n","INFO:__main__: IoUs: [0.90299469 0.64184057]\n","INFO:__main__: Val epoch: 29\tMean IoU: 0.772\n","INFO:__main__: Train epoch: 30 [0/69]\tAvg. Loss: 0.086\tAvg. Time: 2.370\n","INFO:__main__: IoUs: [0.90528438 0.65825027]\n","INFO:__main__: Val epoch: 30\tMean IoU: 0.782\n","INFO:__main__: Train epoch: 31 [0/69]\tAvg. Loss: 0.073\tAvg. Time: 2.448\n","INFO:__main__: IoUs: [0.8988162  0.65283571]\n","INFO:__main__: Val epoch: 31\tMean IoU: 0.776\n","INFO:__main__: Train epoch: 32 [0/69]\tAvg. Loss: 0.082\tAvg. Time: 2.394\n","INFO:__main__: IoUs: [0.90538369 0.65402462]\n","INFO:__main__: Val epoch: 32\tMean IoU: 0.780\n","INFO:__main__: Train epoch: 33 [0/69]\tAvg. Loss: 0.084\tAvg. Time: 2.344\n","INFO:__main__: IoUs: [0.90404664 0.66234194]\n","INFO:__main__: Val epoch: 33\tMean IoU: 0.783\n","INFO:__main__: Train epoch: 34 [0/69]\tAvg. Loss: 0.086\tAvg. Time: 2.455\n","INFO:__main__: IoUs: [0.90667411 0.66037435]\n","INFO:__main__: Val epoch: 34\tMean IoU: 0.784\n","INFO:__main__: Train epoch: 35 [0/69]\tAvg. Loss: 0.040\tAvg. Time: 2.441\n","INFO:__main__: IoUs: [0.90296448 0.63659861]\n","INFO:__main__: Val epoch: 35\tMean IoU: 0.770\n","INFO:__main__: Train epoch: 36 [0/69]\tAvg. Loss: 0.068\tAvg. Time: 2.362\n","INFO:__main__: IoUs: [0.90521738 0.65541395]\n","INFO:__main__: Val epoch: 36\tMean IoU: 0.780\n","INFO:__main__: Train epoch: 37 [0/69]\tAvg. Loss: 0.052\tAvg. Time: 2.303\n","INFO:__main__: IoUs: [0.9040085  0.64798901]\n","INFO:__main__: Val epoch: 37\tMean IoU: 0.776\n","INFO:__main__: Train epoch: 38 [0/69]\tAvg. Loss: 0.032\tAvg. Time: 2.308\n","INFO:__main__: IoUs: [0.90442415 0.65567523]\n","INFO:__main__: Val epoch: 38\tMean IoU: 0.780\n","INFO:__main__: Train epoch: 39 [0/69]\tAvg. Loss: 0.046\tAvg. Time: 2.359\n","INFO:__main__: IoUs: [0.90584389 0.66585508]\n","INFO:__main__: Val epoch: 39\tMean IoU: 0.786\n","INFO:__main__: Train epoch: 40 [0/69]\tAvg. Loss: 0.062\tAvg. Time: 2.359\n","INFO:__main__: IoUs: [0.9051365  0.65633417]\n","INFO:__main__: Val epoch: 40\tMean IoU: 0.781\n","INFO:__main__: Train epoch: 41 [0/69]\tAvg. Loss: 0.046\tAvg. Time: 2.360\n","INFO:__main__: IoUs: [0.90387194 0.65946945]\n","INFO:__main__: Val epoch: 41\tMean IoU: 0.782\n","INFO:__main__: Train epoch: 42 [0/69]\tAvg. Loss: 0.068\tAvg. Time: 2.432\n","INFO:__main__: IoUs: [0.9059671  0.66095038]\n","INFO:__main__: Val epoch: 42\tMean IoU: 0.783\n","INFO:__main__: Train epoch: 43 [0/69]\tAvg. Loss: 0.057\tAvg. Time: 2.405\n","INFO:__main__: IoUs: [0.90508197 0.6641398 ]\n","INFO:__main__: Val epoch: 43\tMean IoU: 0.785\n","INFO:__main__: Train epoch: 44 [0/69]\tAvg. Loss: 0.066\tAvg. Time: 2.424\n","INFO:__main__: IoUs: [0.87673402 0.5801002 ]\n","INFO:__main__: Val epoch: 44\tMean IoU: 0.728\n","INFO:__main__: Train epoch: 45 [0/69]\tAvg. Loss: 0.097\tAvg. Time: 2.462\n","INFO:__main__: IoUs: [0.88465034 0.61158896]\n","INFO:__main__: Val epoch: 45\tMean IoU: 0.748\n","INFO:__main__: Train epoch: 46 [0/69]\tAvg. Loss: 0.067\tAvg. Time: 2.334\n","INFO:__main__: IoUs: [0.90493022 0.66356218]\n","INFO:__main__: Val epoch: 46\tMean IoU: 0.784\n","INFO:__main__: Train epoch: 47 [0/69]\tAvg. Loss: 0.087\tAvg. Time: 2.389\n","INFO:__main__: IoUs: [0.90494539 0.65088412]\n","INFO:__main__: Val epoch: 47\tMean IoU: 0.778\n","INFO:__main__: Train epoch: 48 [0/69]\tAvg. Loss: 0.062\tAvg. Time: 2.415\n","INFO:__main__: IoUs: [0.88615901 0.6253623 ]\n","INFO:__main__: Val epoch: 48\tMean IoU: 0.756\n","INFO:__main__: Train epoch: 49 [0/69]\tAvg. Loss: 0.063\tAvg. Time: 2.417\n","INFO:__main__: IoUs: [0.90507455 0.6549827 ]\n","INFO:__main__: Val epoch: 49\tMean IoU: 0.780\n","INFO:__main__: Train epoch: 50 [0/69]\tAvg. Loss: 0.065\tAvg. Time: 2.456\n","INFO:__main__: IoUs: [0.90581606 0.65477271]\n","INFO:__main__: Val epoch: 50\tMean IoU: 0.780\n","INFO:__main__: Train epoch: 51 [0/69]\tAvg. Loss: 0.058\tAvg. Time: 2.591\n","INFO:__main__: IoUs: [0.90476723 0.66542399]\n","INFO:__main__: Val epoch: 51\tMean IoU: 0.785\n","INFO:__main__: Train epoch: 52 [0/69]\tAvg. Loss: 0.102\tAvg. Time: 2.370\n","INFO:__main__: IoUs: [0.88470289 0.61534774]\n","INFO:__main__: Val epoch: 52\tMean IoU: 0.750\n","INFO:__main__: Train epoch: 53 [0/69]\tAvg. Loss: 0.061\tAvg. Time: 2.311\n","INFO:__main__: IoUs: [0.90336812 0.66871901]\n","INFO:__main__: Val epoch: 53\tMean IoU: 0.786\n","INFO:__main__: Train epoch: 54 [0/69]\tAvg. Loss: 0.076\tAvg. Time: 2.411\n","INFO:__main__: IoUs: [0.88636756 0.62592542]\n","INFO:__main__: Val epoch: 54\tMean IoU: 0.756\n","INFO:__main__: Train epoch: 55 [0/69]\tAvg. Loss: 0.044\tAvg. Time: 2.367\n","INFO:__main__: IoUs: [0.88296769 0.60515092]\n","INFO:__main__: Val epoch: 55\tMean IoU: 0.744\n","INFO:__main__: Train epoch: 56 [0/69]\tAvg. Loss: 0.069\tAvg. Time: 2.365\n","INFO:__main__: IoUs: [0.90756656 0.6670434 ]\n","INFO:__main__: Val epoch: 56\tMean IoU: 0.787\n","INFO:__main__: Train epoch: 57 [0/69]\tAvg. Loss: 0.040\tAvg. Time: 2.317\n","INFO:__main__: IoUs: [0.88765743 0.62405164]\n","INFO:__main__: Val epoch: 57\tMean IoU: 0.756\n","INFO:__main__: Train epoch: 58 [0/69]\tAvg. Loss: 0.039\tAvg. Time: 2.312\n","INFO:__main__: IoUs: [0.88725522 0.62937693]\n","INFO:__main__: Val epoch: 58\tMean IoU: 0.758\n","INFO:__main__: Train epoch: 59 [0/69]\tAvg. Loss: 0.053\tAvg. Time: 2.415\n","INFO:__main__: IoUs: [0.90552706 0.65717968]\n","INFO:__main__: Val epoch: 59\tMean IoU: 0.781\n","INFO:__main__: Train epoch: 60 [0/69]\tAvg. Loss: 0.053\tAvg. Time: 2.334\n","INFO:__main__: IoUs: [0.90673497 0.67130525]\n","INFO:__main__: Val epoch: 60\tMean IoU: 0.789\n","INFO:__main__: Train epoch: 61 [0/69]\tAvg. Loss: 0.044\tAvg. Time: 2.368\n","INFO:__main__: IoUs: [0.90709666 0.66221772]\n","INFO:__main__: Val epoch: 61\tMean IoU: 0.785\n","INFO:__main__: Train epoch: 62 [0/69]\tAvg. Loss: 0.029\tAvg. Time: 2.346\n","INFO:__main__: IoUs: [0.88694685 0.62664339]\n","INFO:__main__: Val epoch: 62\tMean IoU: 0.757\n","INFO:__main__: Train epoch: 63 [0/69]\tAvg. Loss: 0.051\tAvg. Time: 2.399\n","INFO:__main__: IoUs: [0.90707808 0.66442232]\n","INFO:__main__: Val epoch: 63\tMean IoU: 0.786\n","INFO:__main__: Train epoch: 64 [0/69]\tAvg. Loss: 0.065\tAvg. Time: 2.316\n","INFO:__main__: IoUs: [0.90547503 0.6672358 ]\n","INFO:__main__: Val epoch: 64\tMean IoU: 0.786\n","INFO:__main__: Train epoch: 65 [0/69]\tAvg. Loss: 0.080\tAvg. Time: 2.349\n","INFO:__main__: IoUs: [0.88727457 0.62870287]\n","INFO:__main__: Val epoch: 65\tMean IoU: 0.758\n"],"name":"stderr"}]}]}