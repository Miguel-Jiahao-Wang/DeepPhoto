{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TestingCustomModels.ipynb","provenance":[],"collapsed_sections":["UvgxU7GsQ2oD","dHzES-veQ-9K","a3U3Te6rRC87"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"48AK4U8VQzKl","colab_type":"text"},"source":["# Testing custom models"]},{"cell_type":"markdown","metadata":{"id":"UvgxU7GsQ2oD","colab_type":"text"},"source":["## Setup and imports"]},{"cell_type":"code","metadata":{"id":"jszW3Tavyxa_","colab_type":"code","outputId":"889c2186-0b79-48b1-c4d7-e6b93b027b1d","executionInfo":{"status":"ok","timestamp":1573481973188,"user_tz":-60,"elapsed":18517,"user":{"displayName":"Ching Yu LIN","photoUrl":"","userId":"03658548724397829095"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GD3_oqs1y2WU","colab_type":"code","outputId":"da25bec5-d94d-42f0-8918-868970c85d48","executionInfo":{"status":"ok","timestamp":1573481974842,"user_tz":-60,"elapsed":20135,"user":{"displayName":"Ching Yu LIN","photoUrl":"","userId":"03658548724397829095"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/DeepLearningX/gitclone/light-weight-refinenet/src"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/DeepLearningX/gitclone/light-weight-refinenet/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cAREVWSmycRJ","colab_type":"code","colab":{}},"source":["# general libs\n","import argparse\n","import logging\n","import os\n","import random\n","import re\n","import sys\n","import time\n","\n","# misc\n","import cv2\n","import numpy as np\n","\n","# pytorch libs\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import confusion_matrix\n","\n","# custom libs\n","from util import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dHzES-veQ-9K","colab_type":"text"},"source":["\n","## Methods for testing"]},{"cell_type":"code","metadata":{"id":"pbEIjd8F3q6M","colab_type":"code","colab":{}},"source":["# defining methods for testing\n","sys.path.append(\"..\")\n","\n","from models.mobilenet import mbv2\n","from models.resnet import rf_lw50, rf_lw101, rf_lw152\n","\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, random_split\n","# Custom libraries\n","from datasets import NYUDataset as Dataset\n","from datasets import Pad, RandomCrop, RandomMirror, ResizeShorterScale, ToTensor, Normalise\n","\n","def create_loaders(\n","    val_dir, val_list,\n","    shorter_side, crop_size, low_scale, high_scale,\n","    normalise_params, batch_size, num_workers, ignore_label\n","    ):\n","    \"\"\"\n","    Args:\n","      train_dir (str) : path to the root directory of the training set.\n","      val_dir (str) : path to the root directory of the validation set.\n","      train_list (str) : path to the training list.\n","      val_list (str) : path to the validation list.\n","      shorter_side (int) : parameter of the shorter_side resize transformation.\n","      crop_size (int) : square crop to apply during the training.\n","      low_scale (float) : lowest scale ratio for augmentations.\n","      high_scale (float) : highest scale ratio for augmentations.\n","      normalise_params (list / tuple) : img_scale, img_mean, img_std.\n","      batch_size (int) : training batch size.\n","      num_workers (int) : number of workers to parallelise data loading operations.\n","      ignore_label (int) : label to pad segmentation masks with\n","\n","    Returns:\n","      train_loader, val loader\n","\n","    \"\"\"\n","    composed_val = transforms.Compose([Normalise(*normalise_params),\n","                                    ToTensor()])\n","    valset = Dataset(data_file=val_list,\n","                         data_dir=val_dir,\n","                         transform_trn=None,\n","                         transform_val=composed_val)\n","    logger.info(\" Created val set = {} examples\"\n","                .format(len(valset)))\n","    ## Training and validation loaders ##\n","\n","    val_loader = DataLoader(valset,\n","                            batch_size=1,\n","                            shuffle=False,\n","                            num_workers=num_workers,\n","                            pin_memory=True)\n","    return val_loader\n","\n","def compute_iu(cm):\n","    \"\"\"Compute IU from confusion matrix.\n","\n","    Args:\n","      cm (Tensor) : square confusion matrix.\n","\n","    Returns:\n","      IU vector (Tensor).\n","\n","    \"\"\"\n","    pi = 0\n","    gi = 0\n","    ii = 0\n","    denom = 0\n","    n_classes = cm.shape[0]\n","    IU = np.ones(n_classes)\n","    \n","    for i in range(n_classes):\n","        pi = sum(cm[:, i])\n","        gi = sum(cm[i, :])\n","        ii = cm[i, i]\n","        denom = pi + gi - ii\n","        if denom > 0:\n","            IU[i] = ii / denom\n","    return IU\n","\n","def validate(\n","    segmenter, val_loader, epoch, path, num_classes=-1\n","    ):\n","    \"\"\"Validate segmenter\n","\n","    Args:\n","      segmenter (nn.Module) : segmentation network\n","      val_loader (DataLoader) : training data iterator\n","      epoch (int) : current epoch\n","      num_classes (int) : number of classes to consider\n","\n","    Returns:\n","      Mean IoU (float)\n","    \"\"\"\n","    val_loader.dataset.set_stage('val')\n","    segmenter.eval()\n","    cm = np.zeros((num_classes, num_classes), dtype=int)\n","    cmList = []\n","    times = []\n","    with torch.no_grad():\n","        for i, sample in enumerate(val_loader):\n","            start = time.time()\n","            input = sample['image']\n","            target = sample['mask']\n","            input_var = torch.autograd.Variable(input).float().cuda()\n","            # Compute output\n","            start = time.time()\n","            output = segmenter(input_var)\n","            end = time.time()\n","            times.append((end-start)*1.)\n","            output = cv2.resize(output[0, :num_classes].data.cpu().numpy().transpose(1, 2, 0),\n","                                target.size()[1:][::-1],\n","                                interpolation=cv2.INTER_CUBIC).argmax(axis=2).astype(np.uint8)\n","            # Compute IoU\n","            gt = target[0].data.cpu().numpy().astype(np.uint8)\n","            gt_idx = gt < num_classes # Ignore every class index larger than the number of classes\n","            cm += confusion_matrix(output[gt_idx], gt[gt_idx])\n","            cmList.append(np.mean( compute_iu( confusion_matrix(output[gt_idx], gt[gt_idx]) ) ))\n","            \n","            # if i % PRINT_EVERY == 0:\n","            #     logger.info(' Val epoch: {} [{}/{}]\\t'\n","            #                 'Mean IoU: {:.3f}'.format(\n","            #                     epoch, i, len(val_loader),\n","            #                     compute_iu(cm).mean()\n","            #                 ))\n","\n","    ious = compute_iu(cm)\n","    logger.info(\" IoUs: {}\".format(ious))\n","    miou = np.mean(ious)\n","    \n","    with open(path, 'a') as f:\n","      f.write(\"{}\\n\".format(miou))\n","\n","    logger.info(' Val epoch: {}\\tMean IoU: {:.3f}'.format(\n","                                epoch, miou))\n","    return miou, cmList, times"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a3U3Te6rRC87","colab_type":"text"},"source":["## Loading models, configurations and testing"]},{"cell_type":"code","metadata":{"id":"vLgz4BUZzRQY","colab_type":"code","colab":{}},"source":["mob = torch.load(\"/content/drive/My Drive/DeepLearningX/models/MobileNet/model_44\")\n","mobFreeze = torch.load(\"/content/drive/My Drive/DeepLearningX/models/MobileNet/modelFreeze_17\")\n","\n","rest50 = torch.load(\"/content/drive/My Drive/DeepLearningX/models/ResNet/model_res50_unfreezed_23\")\n","rest50Freeze = torch.load(\"/content/drive/My Drive/DeepLearningX/models/ResNet/model_res50_freezed_31\")\n","\n","rest101 = torch.load(\"/content/drive/My Drive/DeepLearningX/models/ResNet/model_res101_unfreezed_6\")\n","rest101Freeze = torch.load(\"/content/drive/My Drive/DeepLearningX/models/ResNet/model_res101_freezed_31\")\n","\n","rest152 = torch.load(\"/content/drive/My Drive/DeepLearningX/models/ResNet/model_res152_unfreezed_54\")\n","rest152Freeze = torch.load(\"/content/drive/My Drive/DeepLearningX/models/ResNet/model_res152_freezed_82\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PrznLXF62R9L","colab_type":"code","colab":{}},"source":["models = [mob, mobFreeze, rest50, rest50Freeze, rest101, rest101Freeze, rest152, rest152Freeze]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmghLpN_6LU0","colab_type":"code","colab":{}},"source":["VAL_DIR = \"/content/drive/My Drive/DeepLearningX/TrainData-People/Test/\"\n","VAL_LIST = \"/content/drive/My Drive/DeepLearningX/TrainData-People/Test/Test.txt\"\n","metricPath = '/content/drive/My Drive/DeepLearningX/models/'\n","\n","SHORTER_SIDE = 350\n","CROP_SIZE = 500\n","NORMALISE_PARAMS = [1./255, # SCALE\n","                    np.array([0.485, 0.456, 0.406]).reshape((1, 1, 3)), # MEAN\n","                    np.array([0.229, 0.224, 0.225]).reshape((1, 1, 3))] # STD\n","BATCH_SIZE = 10\n","NUM_WORKERS = 16\n","NUM_CLASSES = 21\n","LOW_SCALE = 0.5\n","HIGH_SCALE = 2.0\n","IGNORE_LABEL = 255\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWDNRcaA2Kpp","colab_type":"code","outputId":"c9f8a788-4e0b-4830-f16c-e43165e92179","executionInfo":{"status":"ok","timestamp":1573482476130,"user_tz":-60,"elapsed":327597,"user":{"displayName":"Ching Yu LIN","photoUrl":"","userId":"03658548724397829095"}},"colab":{"base_uri":"https://localhost:8080/","height":561}},"source":["logging.basicConfig(level=logging.INFO)\n","global logger \n","logger = logging.getLogger(__name__)\n","\n","mious = []\n","ious = []\n","times = []\n","tppList =[]\n","\n","for model in models:\n","\n","  ## Generate Segmenter ##\n","  segmenter = model\n","\n","  val_loader = create_loaders(VAL_DIR,\n","                              VAL_LIST,\n","                              SHORTER_SIDE,\n","                              CROP_SIZE,\n","                              LOW_SCALE,\n","                              HIGH_SCALE,\n","                              NORMALISE_PARAMS,\n","                              BATCH_SIZE,\n","                              NUM_WORKERS,\n","                              IGNORE_LABEL)\n","\n","  start = time.time()\n","  miou, cmList, tpp = validate(segmenter, val_loader, 0, metricPath + \"mious_test.txt\", 2)\n","  end = time.time()\n","  logger.info(\"Stage  finished, time spent {:.3f}min, avg time per picture {:.5f}sec\".format(\n","            (end - start) / 60., np.mean(tpp)))\n","  mious.append(miou)\n","  ious.append(cmList)\n","  times.append((end-start) / 60.)\n","  tppList.append(tpp)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:__main__: Created val set = 104 examples\n","INFO:__main__: IoUs: [0.90915827 0.70786982]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.809\n","INFO:__main__:Stage  finished, time spent 0.760min, avg time per picture 0.01562sec\n","INFO:__main__: Created val set = 104 examples\n","INFO:__main__: IoUs: [0.90958184 0.70624557]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.808\n","INFO:__main__:Stage  finished, time spent 0.598min, avg time per picture 0.02273sec\n","INFO:__main__: Created val set = 104 examples\n","INFO:__main__: IoUs: [0.91460936 0.71157932]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.813\n","INFO:__main__:Stage  finished, time spent 0.656min, avg time per picture 0.02400sec\n","INFO:__main__: Created val set = 104 examples\n","INFO:__main__: IoUs: [0.91836034 0.71161172]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.815\n","INFO:__main__:Stage  finished, time spent 0.653min, avg time per picture 0.02401sec\n","INFO:__main__: Created val set = 104 examples\n","INFO:__main__: IoUs: [0.89231874 0.66038141]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.776\n","INFO:__main__:Stage  finished, time spent 0.674min, avg time per picture 0.03822sec\n","INFO:__main__: Created val set = 104 examples\n","INFO:__main__: IoUs: [0.93311631 0.76121919]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.847\n","INFO:__main__:Stage  finished, time spent 0.672min, avg time per picture 0.03836sec\n","INFO:__main__: Created val set = 104 examples\n","INFO:__main__: IoUs: [0.93906309 0.77857944]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.859\n","INFO:__main__:Stage  finished, time spent 0.717min, avg time per picture 0.05025sec\n","INFO:__main__: Created val set = 104 examples\n","INFO:__main__: IoUs: [0.90886194 0.70115691]\n","INFO:__main__: Val epoch: 0\tMean IoU: 0.805\n","INFO:__main__:Stage  finished, time spent 0.718min, avg time per picture 0.04620sec\n"],"name":"stderr"}]}]}